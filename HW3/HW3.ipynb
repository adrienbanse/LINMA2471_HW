{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from keras.datasets import mnist\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "printed = False\n",
    "\n",
    "def gradient_f(x_k, mu,lam,a,b):\n",
    "    nA = len(a)\n",
    "    nB = len(b)\n",
    "    n = len(a[0])\n",
    "    h, c, s, t, l = x_k[:n], x_k[n], x_k[n + 1:n + 1 + nA], x_k[n + 1 + nA:n + 1 + nA + nB], x_k[-1]\n",
    "    den_A = 1 / (- 1 - a @ h - c + s)\n",
    "    den_B = 1 / (- 1 + b @ h + c + t)\n",
    "    den_L = 1 / (l * l - h.T @ h)\n",
    "\n",
    "    dfdh = np.sum(a.T * den_A, axis=1) - np.sum(b.T * den_B, axis=1) + 2 * h * den_L\n",
    "    dfdc = np.sum(den_A) - np.sum(den_B)\n",
    "    dfds = 1 / (nA * mu) - 1 / s - den_A\n",
    "    dfdt = 1 / (nB * mu) - 1 / t - den_B\n",
    "    dfdl = lam / mu - 2 * l * den_L\n",
    "\n",
    "    return np.hstack([dfdh, dfdc, dfds, dfdt, dfdl])\n",
    "\n",
    "def hessian_f(x_k,a,b):\n",
    "    nA = len(a)\n",
    "    nB = len(b)\n",
    "    n = len(a[0])\n",
    "\n",
    "    h,c,s,t,l=x_k[:n], x_k[n], x_k[n + 1:n + 1 + nA], x_k[n + 1 + nA:n + 1 + nA + nB], x_k[-1]\n",
    "\n",
    "    den_A = 1 / (- 1 - a @ h - c + s)\n",
    "    den_A2 = den_A * den_A\n",
    "    den_B = 1 / (- 1 + b @ h + c + t)\n",
    "    den_B2 = den_B * den_B\n",
    "    den_L = 1 / (l * l - np.dot(h, h))\n",
    "    den_L2 = den_L * den_L\n",
    "\n",
    "    dfdhdh = (a.T*den_A2) @ a + (b.T * den_B2) @ b + np.outer(h, h) * 4 * den_L2 + 2 * den_L * np.eye(n)\n",
    "    dfdhdc = np.sum(a.T * den_A2, axis=1) + np.sum(b.T * den_B2, axis=1)\n",
    "    dfdhds = -a.T @ np.diag(den_A2)\n",
    "    dfdhdt = b.T @ np.diag(den_B2)\n",
    "    dfdhdl = -4 * l * h * den_L2\n",
    "    dfdcdc = np.sum(den_A2) + np.sum(den_B2)\n",
    "    dfdcds = -den_A2\n",
    "    dfdcdt = den_B2\n",
    "    dfdsds = np.diag(1/(s*s) +  den_A2)\n",
    "    dfdtdt = np.diag(1/(t*t) +  den_B2)\n",
    "    dfdldl = (2 * l * l + 2 * np.dot(h, h)) * den_L2\n",
    "\n",
    "    hessian = np.zeros((n + nA + nB + 2, n + nA + nB + 2))\n",
    "    # dfdhdh\n",
    "    hessian[:n, :n] = dfdhdh\n",
    "    # dfdhdc/dfdcdh\n",
    "    hessian[:n, n] = dfdhdc\n",
    "    hessian[n, :n] = dfdhdc\n",
    "    # dfdhds/dfdsdh\n",
    "    hessian[:n, n + 1:n + 1 + nA] = dfdhds\n",
    "    hessian[n + 1:n + 1 + nA, :n] = dfdhds.T\n",
    "    # dfdhdt/dfdtdh\n",
    "    hessian[: n, n + 1 + nA: n + 1 + nA + nB] = dfdhdt\n",
    "    hessian[n + 1 + nA: n + 1 + nA + nB, : n] = dfdhdt.T\n",
    "    # dfdhdl/dfdldh\n",
    "    hessian[: n, -1] = dfdhdl\n",
    "    hessian[-1, : n] = dfdhdl\n",
    "    # dfdcdc\n",
    "    hessian[n, n] = dfdcdc\n",
    "    # dfdcds/dfdsdc\n",
    "    hessian[n + 1:n + 1 + nA, n] = dfdcds\n",
    "    hessian[n, n + 1:n + 1 + nA] = dfdcds\n",
    "    # dfdcdt/dfdtdc\n",
    "    hessian[n + 1 + nA:n + 1 + nA + nB, n] = dfdcdt\n",
    "    hessian[n, n + 1 + nA:n + 1 + nA + nB] = dfdcdt\n",
    "    #dfdsds\n",
    "    hessian[n+1:n+1+nA,n+1:n+1+nA] = dfdsds\n",
    "    #dfdtdt\n",
    "    hessian[n + 1 + nA:n + 1 + nA + nB, n + 1 + nA:n + 1 + nA + nB] = dfdtdt\n",
    "    #dfdldl\n",
    "    hessian[-1,-1]=dfdldl\n",
    "\n",
    "    return hessian"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def initial_point(lam,nA,nB,n):\n",
    "    var = np.zeros(n + 2 + nA + nB)\n",
    "    var[n + 1:n + 1 + nA] = lam * (1 - nA / (nA + nB))\n",
    "    var[n + 1 + nA:n + 1 + nA + nB] = lam * (nA / nB) * (1 - nA / (nA + nB))\n",
    "    var[-1] = 1\n",
    "    return var\n",
    "\n",
    "def predict(x, h, c):\n",
    "    labels = -1 * np.ones(len(x))\n",
    "    for i in range(len(x)):\n",
    "        if np.dot(h, x[i]) + c <= 0:\n",
    "            labels[i] = 0\n",
    "        elif np.dot(h, x[i]) + c >= 0:\n",
    "            labels[i] = 1\n",
    "    return labels\n",
    "\n",
    "def accuracy(h,c,a,b):\n",
    "    nA = len(a)\n",
    "    nB = len(b)\n",
    "    pred_labels_a = predict(a, h, c)\n",
    "    pred_labels_b = predict(b, h, c)\n",
    "    acc_a = len(np.where(pred_labels_a == 0)[0])\n",
    "    acc_b = len(np.where(pred_labels_b == 1)[0])\n",
    "    print('     Accuracy  : %1.8f (A : %1.8f,B : %1.8f)' %((acc_a+acc_b)/(nA+nB),acc_a/nA,acc_b/nB))\n",
    "    return (acc_a+acc_b)/(nA+nB)\n",
    "\n",
    "def newton(x_k,mu_k,lam,a,b,damped=False):\n",
    "    hess = hessian_f(x_k,a,b)\n",
    "    grad = gradient_f(x_k, mu_k,lam,a,b)\n",
    "    n_x = -np.linalg.solve(hess, grad)\n",
    "    if damped:\n",
    "        delt = np.sqrt(-np.dot(grad, n_x))\n",
    "        x_k += 1 / (1 + delt) * n_x\n",
    "        return x_k,delt\n",
    "    else:\n",
    "        return x_k + n_x\n",
    "\n",
    "def fit(lam,mu_0,a,b,epsilon,num_theta):\n",
    "    tau = 0.25\n",
    "\n",
    "    nA = len(a)\n",
    "    nB = len(b)\n",
    "    n = len(a[0])\n",
    "    nu = 2 * (nA + nB + 1)\n",
    "\n",
    "    theta = num_theta / (1 * np.sqrt(nu))\n",
    "    x_k = initial_point(lam,nA,nB,n)\n",
    "\n",
    "    delt = tau + 1\n",
    "    k = 1\n",
    "    while delt > tau:\n",
    "\n",
    "        x_k, delt = newton(x_k,mu_0,lam,a,b,True) # damped\n",
    "        if k%100 == 0 :\n",
    "            print('--------------- Iteration %3.f (damped in progress) ----------------' % k)\n",
    "            print('     Delta : %3.4f' %delt, '(threshold : %3.4f)' %tau)\n",
    "            accuracy(x_k[:n], x_k[n], a, b)\n",
    "        k+=1\n",
    "    mu_final = epsilon * (1 - tau) / nu\n",
    "    mu_k = mu_0\n",
    "    k = 1\n",
    "    while mu_k > mu_final:\n",
    "        if k % 100 == 0 :\n",
    "            print('------------------- Iteration %3.f (damped done) -------------------' % k)\n",
    "            print('     Mu : %1.9f' %mu_k,'(threshold : %1.9f)' %mu_final)\n",
    "            accuracy(x_k[:n], x_k[n], a, b)\n",
    "        mu_k *= (1 - theta)\n",
    "        x_k = newton(x_k, mu_k,lam,a,b)\n",
    "\n",
    "        k+=1\n",
    "\n",
    "    return x_k[:n],x_k[n],accuracy(x_k[:n], x_k[n], a, b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# (train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "# size = 6000\n",
    "# size_class = int(size/2)\n",
    "# ind_a = np.where(train_y == 0)[0][:size_class]\n",
    "# ind_b = np.where(train_y != 0)[0][:size_class]\n",
    "# train_X = np.array(np.reshape(train_X[np.hstack([ind_a, ind_b])],(size,784)),dtype=float)\n",
    "# a_train = train_X[:size_class]\n",
    "# b_train = train_X[size_class:]\n",
    "#\n",
    "# ind_a_test = np.where(test_y == 0)[0]\n",
    "# ind_b_test = np.where(test_y != 0)[0]\n",
    "# test_X = np.array(np.reshape(test_X,(len(test_X),784)),dtype=float)\n",
    "# a_test = test_X[ind_a_test]\n",
    "# b_test = test_X[ind_b_test]\n",
    "#\n",
    "# epsilon = 1e-4\n",
    "# num_theta = 1\n",
    "# acc_lam = np.zeros(10)\n",
    "# for i,lam in enumerate([10]):\n",
    "#     h,c,acc = fit(lam, 1, a_train, b_train, epsilon, num_theta)\n",
    "#     print(\"#####################################################################\")\n",
    "#     print(\"#####################################################################\")\n",
    "#     print(lam,acc)\n",
    "#     accuracy(h, c, a_test, b_test)\n",
    "#     #99,91 lambda=4 num_delta = 1\n",
    "#     #99,91 lambda=6 num_delta = 1\n",
    "#     #99,91 lambda=8 num_delta = 5\n",
    "#     #99,91 lambda=10 num_delta = 5\n",
    "#     #99,66 lambda=12 num_delta = 5\n",
    "#     #99,66 lambda=14 num_delta = 5\n",
    "#     #99,66 lambda=16 num_delta = 5\n",
    "#     print(\"#####################################################################\")\n",
    "#     print(\"#####################################################################\")\n",
    "#     acc_lam[i]=acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Multiclass classification ###\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "size = 6000\n",
    "train_X = np.array(np.reshape(train_X, (len(train_X), 784)), dtype=float)\n",
    "\n",
    "idx_X = [np.where(train_y == x)[0][:int(size/10)] for x in range(10)]\n",
    "classifiers_pairs = [(i,j) for i,j in itertools.combinations(range(10), 2)]\n",
    "classifiers_hyperplanes = np.zeros(45,2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_y_pred = -np.ones(45,len(test_y))\n",
    "h = np.zeros(45)\n",
    "c = np.zeros(45)\n",
    "for idx in range(45):\n",
    "    A,B = classifiers_pairs[idx]\n",
    "    a_train = train_X[idx_X[A]]\n",
    "    b_train = train_X[idx_X[B]]\n",
    "    h_idx, c_idx, acc = fit(lam=10, mu_0=1, a=a_train, b=b_train, epsilon=1e-4, num_theta=1)\n",
    "    h[idx] = h_idx\n",
    "    c[idx] = c_idx\n",
    "    pred_idx = predict(test_X,h,c) # 0 -> A , 1 -> B\n",
    "    test_y_pred[idx] = A * (pred_idx==0) + B * (pred_idx==1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_y = np.zeros(len(test_y))\n",
    "for i in range(len(test_y)) :\n",
    "    pred_y[i] = np.bincount(test_y_pred[:][i]).argmax()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(test_y,pred_y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}